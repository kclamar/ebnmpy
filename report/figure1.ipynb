{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "from ebnmpy.estimators import estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_point_normal(n, pi0=.9, mu=0, sigma=2):\n",
    "    not_delta = stats.bernoulli.rvs(pi0, size=n) == 0\n",
    "    z = np.full(n, mu, dtype=float)\n",
    "    z[not_delta] = stats.norm.rvs(mu, sigma, size=not_delta.sum())\n",
    "    return z\n",
    "\n",
    "def sample_point_t(n, pi0=.8, df=5, scale=1.5):\n",
    "    not_delta = stats.bernoulli.rvs(pi0, size=n) == 0\n",
    "    z = np.zeros(n)\n",
    "    z[not_delta] = stats.t.rvs(df=df, scale=scale, size=not_delta.sum())\n",
    "    return z\n",
    "\n",
    "def sample_assymetric_tophat(n, pi0=.5, a=-5, b=10):\n",
    "    not_delta = stats.bernoulli.rvs(pi0, size=n) == 0\n",
    "    z = np.zeros(n)\n",
    "    z[not_delta] = stats.uniform.rvs(a, b - a, size=not_delta.sum())\n",
    "    return z\n",
    "\n",
    "def get_rmse(theta, theta_hat):\n",
    "    return np.sqrt(np.mean((theta_hat - theta) ** 2))\n",
    "\n",
    "def get_clcov(theta, samples, intervals=(.05, .95)):\n",
    "    lower = np.quantile(samples, intervals[0], axis=0)\n",
    "    upper = np.quantile(samples, intervals[1], axis=0)\n",
    "    return ((theta >= lower) & (theta <= upper)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5183eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1\n",
    "n = 1000\n",
    "n_posterior_samples = 1001\n",
    "n_simulations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e9b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = {\n",
    "    \"Point-normal\": sample_point_normal,\n",
    "    \"Point-t\": sample_point_t,\n",
    "    \"Asymmetric tophat\": sample_assymetric_tophat,\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for _ in range(n_simulations):\n",
    "    for sampler_name, sampler in samplers.items():\n",
    "        theta = sampler(n)\n",
    "        x = theta + stats.norm.rvs(size=n)\n",
    "\n",
    "        for cls_name, cls in estimators.items():\n",
    "            est = cls(include_posterior_sampler=True).fit(x=x, s=s)\n",
    "            samples = est.sample(n_posterior_samples)\n",
    "\n",
    "            loglik = est.log_likelihood_\n",
    "            rmse = get_rmse(theta, theta_hat=est.posterior_[\"mean\"])\n",
    "            clcov = get_clcov(theta, samples)\n",
    "\n",
    "            results.append((sampler_name, cls.__name__, loglik, rmse, clcov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=(\"Distribution\", \"Class\", \"LogLik\", \"RMSE\", \"ClCov\"))\n",
    "columns = list(itertools.product(list(samplers), (\"LogLik\", \"RMSE\", \"ClCov\")))\n",
    "df_mean = df.groupby([\"Distribution\", \"Class\"]).mean().unstack(0).swaplevel(0, 1, axis=1)[columns].loc[[i.__name__ for i in estimators.values()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfc2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean.index.name = None\n",
    "df_mean.columns.names = [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220dcbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter = {i: \"{:.1f}\" if \"LogLik\" in i else \"{:.3f}\" for i in columns}\n",
    "s = df_mean.style.format(formatter=formatter)\n",
    "s = s.background_gradient(cmap=\"Reds_r\", subset=columns[::3]).background_gradient(cmap=\"Reds\", subset=columns[1::3]).background_gradient(cmap=\"Reds_r\", subset=columns[2::3])\n",
    "s = s.set_properties(**{'text-align': 'center'})\n",
    "s = s.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n",
    "for i in (3, 6):\n",
    "    s = s.set_table_styles({\n",
    "        columns[i]: [{'selector': 'th', 'props': 'border-left: 1px solid black'},\n",
    "                                   {'selector': 'td', 'props': 'border-left: 1px solid #000000'}]\n",
    "    }, overwrite=False, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393cc26b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354454a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
